{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Setup Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    def dataAllocation(self,path):\n",
    "        \"\"\"Separate out the x_data and y_data and return each\n",
    "\n",
    "        Args:\n",
    "            path (_type_): string path for .parquet file\n",
    "\n",
    "        Returns:\n",
    "            _type_: pandas dataframe, pandas series\n",
    "        \"\"\"\n",
    "        df = pd.read_parquet(path)\n",
    "\n",
    "        x_data = df.drop(['application_approved'], axis=1)\n",
    "\n",
    "        y_data = df['application_approved']\n",
    "        \n",
    "        return x_data,y_data\n",
    "\n",
    "    def trainSets(self,x_data,y_data):\n",
    "        \n",
    "        \"\"\"Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test\n",
    "\n",
    "        Args:\n",
    "            x_data (_type_): pandas dataframe\n",
    "            y_data (_type_): pandas dataframe\n",
    "\n",
    "        Returns:\n",
    "            _type_: pandas dataframe, pandas dataframe, pandas series, pandas series\n",
    "        \"\"\"\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Split data\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=614, shuffle=True)\n",
    "        #fill any nan values in y with 0\n",
    "        y_train = y_train.fillna(0)\n",
    "\n",
    "        #any nan values in X_train fill with 0\n",
    "        x_train = x_train.fillna(0)\n",
    "\n",
    "        #any nan values in X_train fill with 0\n",
    "        y_test = y_test.fillna(0)\n",
    "\n",
    "        #any nan values in X_test fill with 0\n",
    "        x_test = x_test.fillna(0)\n",
    "\n",
    "\n",
    "        return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data read data\n",
    "\n",
    "datatest = Data()\n",
    "data = r\"C:\\Users\\Forcessofnature\\Downloads\\df_small_encoded.parquet\"\n",
    "\n",
    "# seperate target variable and features \n",
    "\n",
    "x_data,y_data = datatest.dataAllocation(data)\n",
    "\n",
    "# split to train and testing\n",
    "x_train, x_test, y_train, y_test = datatest.trainSets(x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel():\n",
    "    \n",
    "  \n",
    "    def linearClassifier(self,x_train, x_test, y_train):\n",
    "        \"\"\"LinearRegression classifier\n",
    "\n",
    "        Args:\n",
    "            x_train (_type_): pandas series\n",
    "            x_test (_type_): pandas series\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: numpy array, numpy array\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "\n",
    "        model_lr = LinearRegression()\n",
    "\n",
    "        model_lr.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_predict_train = model_lr.predict(x_train)\n",
    "        y_predict_test = model_lr.predict(x_test)\n",
    "\n",
    "        # -------------------------------\n",
    "        return y_predict_train, y_predict_test\n",
    "\n",
    "    def lgTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"accuracy (on the training set) using the accuracy_score method.\n",
    "            Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements\n",
    "\n",
    "        Args:\n",
    "            y_train (_type_): pandas series\n",
    "            y_predict_train (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        # Convert regression predictions to binary classification labels\n",
    "        y_train_pred_class = [1 if y >= 0.5 else 0 for y in y_predict_train]\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred_class)\n",
    "       \n",
    " \n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def lgTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"accuracy (on the testing set) using the accuracy_score method\n",
    "            Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        # Convert regression predictions to binary classification labels\n",
    "        y_test_pred_class = [1 if y >= 0.5 else 0 for y in y_predict_test]\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred_class)\n",
    "             \n",
    "        return test_accuracy\n",
    "    \n",
    "    def lgTestReport(self,y_test,y_predict_test):\n",
    "        \"\"\"Report classification\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        # Convert regression predictions to binary classification labels\n",
    "        y_test_pred_class = [1 if y >= 0.5 else 0 for y in y_predict_test]\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "       \n",
    "        class_report = classification_report(y_test, y_test_pred_class)\n",
    "       \n",
    "        return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearClassifier Function Executed\n",
      "Linear Regression Train Accuracy:  0.8924186148131964\n",
      "Linear Regression Test Accuracy:  0.8926771490726968\n",
      "Linear Regression Test Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.04      0.08    230137\n",
      "           1       0.89      1.00      0.94   1868745\n",
      "\n",
      "    accuracy                           0.89   2098882\n",
      "   macro avg       0.78      0.52      0.51   2098882\n",
      "weighted avg       0.87      0.89      0.85   2098882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear = LinearRegressionModel()\n",
    "y_predict_train, y_predict_test = linear.linearClassifier(x_train,x_test, y_train)\n",
    "print(\"linearClassifier Function Executed\")\n",
    "print(\"Linear Regression Train Accuracy: \", linear.lgTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Linear Regression Test Accuracy: \", linear.lgTestAccuracy(y_test,y_predict_test))\n",
    "print(\"Linear Regression Test Report: \\n\", linear.lgTestReport(y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogsticRegressionModel():\n",
    "    \n",
    "  \n",
    "    def logisticClassifier(self,x_train, x_test, y_train):\n",
    "        \"\"\"Logistic Regression classifier\n",
    "\n",
    "        Args:\n",
    "            x_train (_type_): pandas series\n",
    "            x_test (_type_): pandas series\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: numpy array, numpy array\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "        model_lgr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "        model_lgr.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_predict_train = model_lgr.predict(x_train)\n",
    "        y_predict_test = model_lgr.predict(x_test)\n",
    "\n",
    "        # -------------------------------\n",
    "        return model_lgr, y_predict_train, y_predict_test\n",
    "\n",
    "    def lgTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"accuracy (on the training set) using the accuracy_score method.\n",
    "            Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements\n",
    "\n",
    "        Args:\n",
    "            y_train (_type_): pandas series\n",
    "            y_predict_train (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "        train_accuracy = accuracy_score(y_train, y_predict_train)\n",
    "       \n",
    " \n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def lgTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"accuracy (on the testing set) using the accuracy_score method\n",
    "            Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        \n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "        test_accuracy = accuracy_score(y_test, y_predict_test)\n",
    "       \n",
    "        return test_accuracy\n",
    "    \n",
    "    def lgTestReport(self,y_test,y_predict_test):\n",
    "        \"\"\"Report classification\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "       \n",
    "        class_report = classification_report(y_test, y_predict_test)\n",
    "       \n",
    "        return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Classifier Function Executed\n",
      "Logistic Regression Train Accuracy:  0.8878700695676677\n",
      "Logistic Regression Test Accuracy:  0.8881857102971963\n",
      "Logistic Regression Test Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.02      0.03    230137\n",
      "           1       0.89      1.00      0.94   1868745\n",
      "\n",
      "    accuracy                           0.89   2098882\n",
      "   macro avg       0.60      0.51      0.49   2098882\n",
      "weighted avg       0.83      0.89      0.84   2098882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic = LogsticRegressionModel()\n",
    "model_lgr, y_predict_train, y_predict_test = logistic.logisticClassifier(x_train,x_test, y_train)\n",
    "print(\"Logistic Classifier Function Executed\")\n",
    "print(\"Logistic Regression Train Accuracy: \", logistic.lgTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Logistic Regression Test Accuracy: \", logistic.lgTestAccuracy(y_test,y_predict_test))\n",
    "print(\"Logistic Regression Test Report: \\n\", logistic.lgTestReport(y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15740794686549722"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgr.intercept_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Feature  Coefficient  \\\n",
      "52                                       state_code_TX    -0.448948   \n",
      "4                                           income_log     0.390970   \n",
      "50         race_ethnicity_White|Not Hispanic or Latino     0.373799   \n",
      "57                                  activity_year_2022    -0.354838   \n",
      "43   race_ethnicity_Race Not Available|Hispanic or ...    -0.274510   \n",
      "..                                                 ...          ...   \n",
      "250                                  county_code_42041     0.000000   \n",
      "76                                   county_code_05073     0.000000   \n",
      "152                                  county_code_13297     0.000000   \n",
      "138                                  county_code_08043     0.000000   \n",
      "166                                  county_code_30081     0.000000   \n",
      "\n",
      "     Abs_Coefficient  \n",
      "52          0.448948  \n",
      "4           0.390970  \n",
      "50          0.373799  \n",
      "57          0.354838  \n",
      "43          0.274510  \n",
      "..               ...  \n",
      "250         0.000000  \n",
      "76          0.000000  \n",
      "152         0.000000  \n",
      "138         0.000000  \n",
      "166         0.000000  \n",
      "\n",
      "[572 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficients and corresponding feature names\n",
    "coefficients = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# Extract intercept\n",
    "intercept = model.intercept_[0]\n",
    "\n",
    "\n",
    "# Create a DataFrame to display coefficients and feature names\n",
    "coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "# Sort coefficients by absolute value to identify significant variables\n",
    "coefficients_df['Abs_Coefficient'] = abs(coefficients_df['Coefficient'])\n",
    "coefficients_df = coefficients_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Add intercept to the DataFrame\n",
    "intercept_row = pd.DataFrame({'Feature': 'Intercept', 'Coefficient': intercept, 'Abs_Coefficient': abs(intercept)}, index=[0])\n",
    "coefficients_df = pd.concat([intercept_row, coefficients_df]).reset_index(drop=True)\n",
    "\n",
    "# Display coefficients and feature names\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df.to_csv(r\"C:\\Users\\Forcessofnature\\Downloads\\coef.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFClassifier():\n",
    "    \n",
    "    # points [2]\n",
    "    def randomForestClassifier(self,x_train,x_test, y_train):\n",
    "        \"\"\"RandomForestClassifie\n",
    "\n",
    "        Args:\n",
    "            x_train (_type_): pandas dataframe\n",
    "            x_test (_type_): pandas dataframe\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: RandomForestClassifier object, numpy array, numpy array\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        # Initialize the Random Forest model\n",
    "        rf_clf = RandomForestClassifier(random_state=614)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        rf_clf.fit(x_train, y_train)\n",
    "\n",
    "        # Make predictions on the testing data\n",
    "        y_predict_train = rf_clf.predict(x_train)\n",
    "\n",
    "        y_predict_test = rf_clf.predict(x_test)\n",
    "        \n",
    "        return rf_clf,y_predict_train, y_predict_test\n",
    "    \n",
    "\n",
    "    def rfTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"Return accuracy on the training set using the accuracy_score method\n",
    "\n",
    "        Args:\n",
    "            y_train (_type_): pandas series\n",
    "            y_predict_train (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        # Calculate accuracy on the training set\n",
    "        train_accuracy = accuracy_score(y_train, y_predict_train)\n",
    "        \n",
    "        # -------------------------------\n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def rfTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"Return accuracy on the test set using the accuracy_score method.\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        # Calculate accuracy on the training set\n",
    "        test_accuracy = accuracy_score(y_test, y_predict_test)\n",
    "\n",
    "\n",
    "        return test_accuracy\n",
    "\n",
    "\n",
    "    def rfFeatureImportance(self,rf_clf):\n",
    "        \"\"\"Determine the feature importance as evaluated by the Random Forest Classifier\n",
    "\n",
    "        Args:\n",
    "            rf_clf (_type_): RandomForestClassifier object\n",
    "\n",
    "        Returns:\n",
    "            _type_: float array\n",
    "        \"\"\"\n",
    "\n",
    "        # Get feature importances\n",
    "        feature_importance = rf_clf.feature_importances_\n",
    "        \n",
    "        # -------------------------------\n",
    "        return feature_importance\n",
    "    \n",
    "    # points [1]\n",
    "    def sortedRFFeatureImportanceIndicies(self,rf_clf):\n",
    "        \"\"\"Sorted by descending order and return the feature numbers[0 to ...]\n",
    "\n",
    "        Args:\n",
    "            rf_clf (_type_): RandomForestClassifier object\n",
    "\n",
    "        Returns:\n",
    "            _type_: int array\n",
    "        \"\"\"\n",
    "        # Get feature importances\n",
    "        feature_importance = rf_clf.feature_importances_\n",
    "\n",
    "        # Sort feature importances in descending order\n",
    "        sorted_indices = feature_importance.argsort()[::-1]\n",
    "       \n",
    "        return sorted_indices\n",
    "    \n",
    "    def hyperParameterTuning(self,rf_clf,x_train,y_train):\n",
    "        \"\"\"Tune the hyper-parameters 'n_estimators' and 'max_depth'\n",
    "\n",
    "        Args:\n",
    "            rf_clf (_type_): RandomForestClassifier object\n",
    "            x_train (_type_): pandas dataframe\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: GridSearchCV object\n",
    "        \"\"\"\n",
    "        # param_grid for GridSearchCV as a dictionary\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [4, 16, 256],\n",
    "            'max_depth': [2, 8, 16]\n",
    "        }\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "        # Create GridSearchCV object\n",
    "        gscv_rfc = GridSearchCV(estimator=rf_clf, param_grid=param_grid)\n",
    "\n",
    "        # Fit the GridSearchCV object to the training data\n",
    "        gscv_rfc.fit(x_train, y_train)\n",
    "        \n",
    "        # -------------------------------\n",
    "        return gscv_rfc\n",
    "    \n",
    "    # points [1]\n",
    "    def bestParams(self,gscv_rfc):\n",
    "        \"\"\"best params, using .best_params_\n",
    "\n",
    "        Args:\n",
    "            gscv_rfc (_type_): GridSearchCV object\n",
    "\n",
    "        Returns:\n",
    "            _type_: parameter dict\n",
    "        \"\"\"\n",
    "        best_params = gscv_rfc.best_params_\n",
    "\n",
    "        return best_params\n",
    "    \n",
    "    # points [1]\n",
    "    def bestScore(self,gscv_rfc):\n",
    "        \"\"\"Get the best score, using .best_score_.\n",
    "\n",
    "        Args:\n",
    "            gscv_rfc (_type_): GridSearchCV object\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        best_score = gscv_rfc.best_score_\n",
    "       \n",
    "        return best_score\n",
    "    \n",
    "    def rfTestReport(self,y_test,y_predict_test):\n",
    "        \"\"\"Report classification\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "       \n",
    "        class_report = classification_report(y_test, y_predict_test)\n",
    "       \n",
    "        return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestClassifier Function Executed\n",
      "Random Forest Train Accuracy:  0.9999595703017321\n",
      "Random Forest Test Accuracy:  0.9935070194513079\n",
      "Random Forest Feature Importance:  [4.10985867e-02 4.88773975e-02 4.40321234e-02 6.47568277e-01\n",
      " 3.11932887e-02 5.33863599e-02 4.96450420e-02 5.06218141e-07\n",
      " 4.17722837e-05 1.49428269e-05 9.24794420e-05 3.73402690e-05\n",
      " 1.79327811e-06 1.76694484e-04 1.88988854e-05 1.24987372e-04\n",
      " 1.65304048e-04 1.38035728e-05 1.08356085e-04 7.12511158e-05\n",
      " 1.08213691e-03 4.02825118e-04 9.08270965e-06 1.40095751e-04\n",
      " 8.39937488e-05 1.20654732e-03 1.54787323e-06 1.85093165e-06\n",
      " 1.10198373e-05 9.42023990e-07 5.84368472e-06 5.77527918e-05\n",
      " 6.73439054e-07 8.96105688e-05 1.70403602e-04 3.34185266e-04\n",
      " 1.61015461e-05 3.04076216e-07 5.07725492e-05 1.17027619e-05\n",
      " 1.06104454e-04 1.13499720e-03 3.14405775e-06 2.97984072e-03\n",
      " 1.13987460e-04 3.57542373e-04 5.38524584e-04 1.34802602e-05\n",
      " 1.48916163e-03 4.01700344e-04 2.87761673e-03 1.75157003e-03\n",
      " 2.90029473e-03 1.07354288e-03 2.15534615e-03 2.36397665e-03\n",
      " 2.26047154e-03 2.19147178e-03 2.37601019e-03 6.56316243e-04\n",
      " 1.84886320e-09 1.64493847e-10 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.58263364e-09 0.00000000e+00 0.00000000e+00\n",
      " 3.90831187e-11 1.45120340e-08 4.04329035e-09 0.00000000e+00\n",
      " 5.73108007e-10 7.00226251e-07 3.62584650e-08 0.00000000e+00\n",
      " 1.16076841e-06 0.00000000e+00 0.00000000e+00 1.99601331e-04\n",
      " 3.73645139e-06 4.56577036e-05 7.63369432e-05 4.85129241e-05\n",
      " 1.32538794e-05 2.68674406e-04 2.08489648e-05 9.56895836e-05\n",
      " 3.01662681e-04 1.13484725e-05 3.27859550e-05 9.86694035e-05\n",
      " 1.13220612e-05 2.88163291e-04 6.30298811e-05 4.98023433e-05\n",
      " 2.12966932e-05 7.06071501e-04 9.52237264e-05 4.54094217e-05\n",
      " 1.99065035e-05 3.66844908e-05 1.32522677e-04 8.60243406e-06\n",
      " 1.25852566e-05 1.09762095e-04 5.48304652e-05 5.19051218e-05\n",
      " 3.59940448e-04 1.36126931e-04 2.23470352e-05 5.04328218e-04\n",
      " 3.98248402e-04 4.63188429e-05 4.96868174e-04 4.53481495e-04\n",
      " 8.22531360e-05 2.84611012e-04 1.00059614e-04 9.97411127e-05\n",
      " 1.34214177e-04 1.98510401e-04 6.79065157e-05 7.21966021e-05\n",
      " 2.79654644e-06 2.87606935e-05 1.64712013e-04 1.36579733e-04\n",
      " 2.13005178e-04 5.98092782e-05 3.58537174e-05 6.41991851e-06\n",
      " 1.65280840e-04 4.90853533e-05 2.69786500e-04 7.43512646e-05\n",
      " 7.31083307e-05 2.63650023e-10 2.56249460e-07 1.36215240e-10\n",
      " 0.00000000e+00 8.28606472e-07 1.20490174e-08 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 7.18584167e-09 0.00000000e+00 0.00000000e+00 2.21835717e-08\n",
      " 2.83439218e-07 2.79703477e-08 0.00000000e+00 1.74482363e-07\n",
      " 0.00000000e+00 8.77266408e-11 8.93904985e-08 1.34343959e-06\n",
      " 5.22857622e-08 3.85643324e-08 6.48456399e-08 5.93660703e-11\n",
      " 0.00000000e+00 1.02368350e-06 4.28518942e-07 3.37906356e-07\n",
      " 3.89375476e-08 6.36813117e-07 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 3.62492468e-07 1.44916296e-08 1.70634697e-07 0.00000000e+00\n",
      " 1.07624981e-04 3.18680249e-05 1.39059420e-04 7.69997279e-05\n",
      " 5.12035735e-05 5.19841654e-05 8.54713672e-05 5.02275025e-05\n",
      " 4.21781379e-05 3.32931281e-05 4.29909892e-05 2.32941507e-05\n",
      " 6.12716293e-05 1.45375946e-04 2.17239785e-04 3.45861151e-05\n",
      " 2.47378193e-05 4.18960251e-05 2.99553294e-05 6.32477665e-05\n",
      " 1.11088238e-05 4.05049473e-05 8.26004727e-05 2.03111902e-04\n",
      " 2.51680664e-05 3.13734177e-05 3.54364659e-05 3.27229064e-04\n",
      " 3.43245054e-05 1.93043300e-04 1.20204503e-04 8.15265549e-05\n",
      " 8.31371493e-05 1.76416080e-04 7.69148285e-05 1.89432236e-04\n",
      " 3.02743089e-05 7.41121427e-05 4.88296385e-05 5.49374591e-05\n",
      " 2.29745698e-04 7.46938076e-05 1.19826817e-04 1.23353383e-04\n",
      " 5.15945606e-05 1.41913675e-04 7.64657361e-05 4.46666998e-05\n",
      " 1.66267289e-05 2.87188118e-05 5.92856195e-05 2.63559019e-04\n",
      " 1.23242765e-04 3.09326921e-05 4.62339398e-05 1.42187859e-04\n",
      " 5.03933895e-05 4.76580247e-05 4.94791037e-05 1.96181443e-04\n",
      " 2.98726875e-05 2.23057796e-05 2.44778474e-08 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.37364415e-09 0.00000000e+00\n",
      " 2.40812691e-07 1.82230160e-09 0.00000000e+00 1.47176918e-07\n",
      " 0.00000000e+00 4.64265220e-09 6.09559735e-08 0.00000000e+00\n",
      " 1.08950172e-06 7.42047201e-05 3.88919892e-05 1.11711666e-04\n",
      " 4.45194294e-05 9.56862665e-06 3.73020469e-06 1.94828790e-04\n",
      " 4.14220147e-05 6.44284069e-06 4.63015152e-05 1.68821162e-04\n",
      " 7.24499486e-06 2.93239569e-05 2.40379896e-04 5.60929873e-04\n",
      " 2.16818548e-05 4.76290319e-07 2.95133086e-05 9.98914910e-05\n",
      " 2.20867639e-04 1.16347435e-04 7.48532500e-06 3.22339022e-06\n",
      " 3.31321294e-06 5.09886100e-05 4.70352318e-05 6.24350474e-05\n",
      " 9.61715950e-05 4.49526257e-05 2.72030713e-05 1.60013853e-04\n",
      " 3.39669612e-05 8.79639830e-06 5.09002049e-05 7.73685294e-06\n",
      " 7.82418448e-05 8.44777958e-05 7.42018012e-06 2.00148891e-05\n",
      " 2.67694505e-06 6.66863718e-06 1.58309525e-05 3.37712637e-04\n",
      " 6.16566641e-06 2.89946838e-05 1.49235622e-04 2.23265849e-05\n",
      " 6.37803082e-06 3.83515745e-05 8.01661130e-05 1.74510389e-06\n",
      " 7.64725624e-06 4.58064533e-06 9.26479608e-06 6.49959293e-06\n",
      " 1.09100818e-05 5.55038008e-04 8.25421135e-06 2.18190854e-05\n",
      " 1.40575121e-05 3.13700187e-04 3.25798416e-05 2.67362341e-06\n",
      " 1.27208989e-05 7.79155884e-06 1.17973094e-05 2.58423574e-05\n",
      " 3.76661384e-04 7.32184235e-06 1.79080638e-04 3.29754934e-04\n",
      " 4.35871376e-05 2.56931143e-05 5.22352992e-05 4.22421518e-05\n",
      " 5.35045066e-06 4.46916292e-06 3.84168836e-06 3.06379778e-04\n",
      " 2.87688679e-05 4.54618291e-05 4.73040422e-05 3.90408874e-05\n",
      " 2.07066127e-04 1.63101272e-05 3.64819500e-05 2.54658247e-06\n",
      " 1.45497452e-05 3.71670382e-05 2.99530819e-05 1.21396876e-04\n",
      " 1.03855081e-04 5.21578930e-05 1.55071630e-04 3.06139831e-05\n",
      " 2.74923494e-06 1.16580016e-05 4.55199143e-06 3.84865100e-06\n",
      " 9.48322554e-05 7.04930719e-04 8.97561300e-05 3.84909784e-06\n",
      " 8.47160797e-06 1.90605803e-04 3.94021823e-06 1.35368510e-04\n",
      " 2.02587885e-04 6.65125265e-05 5.17570043e-05 8.62493730e-05\n",
      " 6.49505265e-05 4.11583349e-05 3.41141259e-05 1.00670610e-05\n",
      " 1.43850499e-04 2.61001374e-05 1.37457363e-06 1.42491723e-05\n",
      " 2.29265179e-05 7.85766249e-05 3.53604580e-06 1.24064377e-04\n",
      " 3.41202908e-06 4.20105743e-05 1.70908338e-04 3.82866470e-05\n",
      " 2.27887053e-05 1.96967325e-04 3.61815103e-05 1.21069608e-07\n",
      " 1.06160086e-06 5.79283528e-05 4.81048214e-06 2.25659409e-06\n",
      " 1.27416028e-05 3.64029044e-05 6.63341423e-06 5.04115866e-05\n",
      " 1.17280659e-05 2.58255953e-05 8.74062783e-06 2.93537546e-05\n",
      " 4.33532489e-05 3.78079678e-05 5.71774054e-04 4.93786448e-05\n",
      " 3.21092071e-06 1.68072915e-05 3.42434320e-05 4.18084586e-07\n",
      " 1.77337170e-04 8.97404480e-06 7.87295577e-06 2.20747366e-04\n",
      " 1.18218724e-06 2.60307559e-05 1.94511729e-05 1.44005804e-05\n",
      " 5.65480119e-06 3.60505489e-05 2.81847857e-05 9.61984425e-05\n",
      " 2.52471805e-06 1.89918263e-04 4.08306956e-05 1.20676347e-05\n",
      " 1.52120304e-05 3.18719411e-05 3.32878110e-04 1.79358155e-05\n",
      " 2.48329682e-05 1.29074981e-06 7.40739413e-05 9.10935446e-05\n",
      " 4.70581815e-05 1.75564362e-05 1.97731619e-04 1.49417790e-05\n",
      " 2.12504033e-06 7.55698719e-05 4.31965581e-05 3.76650543e-05\n",
      " 1.35818030e-04 8.16975497e-06 2.54372017e-05 9.33017317e-05\n",
      " 8.52779906e-05 4.61100464e-06 2.90939201e-05 1.07236790e-04\n",
      " 5.05440406e-06 1.23768539e-05 2.66005222e-05 2.24747841e-05\n",
      " 1.53656516e-05 2.31786078e-06 4.12887155e-05 1.05068531e-04\n",
      " 1.02354153e-05 9.23725887e-05 3.24727997e-05 1.88740276e-05\n",
      " 7.36085988e-05 7.68197867e-05 4.34244166e-06 1.18967291e-06\n",
      " 1.84586340e-05 4.77738037e-06 6.18314699e-05 3.96988490e-06\n",
      " 1.75305286e-04 1.35869530e-05 1.84788441e-05 2.73368739e-05\n",
      " 1.81543960e-06 3.57240934e-07 7.83813322e-06 1.10235731e-05\n",
      " 4.77679292e-04 9.36798423e-05 1.58145636e-06 1.45216122e-05\n",
      " 2.95599924e-06 3.74295815e-05 7.24454356e-05 3.94337864e-04\n",
      " 3.51212252e-05 6.02836619e-05 6.40622823e-05 8.96189634e-06\n",
      " 3.14686318e-05 4.96930559e-05 8.97578542e-05 7.17023275e-05\n",
      " 7.12179065e-05 9.83184532e-05 2.28863435e-05 3.96570001e-05\n",
      " 1.40496148e-04 3.98768546e-05 6.30976000e-06 1.67589127e-04\n",
      " 1.46876099e-05 1.16537544e-05 2.66563287e-04 6.80404435e-05\n",
      " 1.88223846e-05 8.44704921e-05 7.01655255e-05 1.50092735e-05\n",
      " 2.36177525e-05 1.15099658e-05 1.29893548e-05 0.00000000e+00\n",
      " 1.83982458e-05 1.38363345e-05 9.16188798e-05 4.80388858e-05\n",
      " 4.02088644e-05 1.48838644e-04 5.43860592e-06 1.10086432e-04\n",
      " 3.11209075e-05 6.56220078e-06 6.66672529e-05 4.76316129e-06\n",
      " 6.89250431e-05 6.78789093e-05 4.35216409e-05 2.55194272e-05\n",
      " 2.67064367e-04 1.02450982e-04 2.85720167e-05 1.86348235e-05\n",
      " 7.11553461e-05 1.54196684e-05 6.56538947e-05 2.92136681e-05\n",
      " 2.91700652e-05 1.59075197e-05 3.03611373e-04 1.62707234e-05\n",
      " 6.82607541e-05 1.06239914e-05 1.70233793e-04 1.66094916e-04\n",
      " 3.75633108e-05 1.29782228e-04 7.85599633e-06 3.59911499e-05\n",
      " 7.97542295e-05 2.25552566e-05 1.05262681e-04 4.14826598e-09\n",
      " 0.00000000e+00 1.14630458e-07 0.00000000e+00 3.69862607e-10\n",
      " 2.14803419e-10 0.00000000e+00 1.58772907e-09 2.10237702e-09\n",
      " 5.59281168e-03 2.25063828e-03 2.08300172e-03 9.40597393e-04\n",
      " 1.75498035e-03 1.81228509e-03 1.47775734e-03 1.35451122e-03\n",
      " 9.76099934e-04 1.01991926e-06 1.04577132e-03 4.51054282e-04]\n",
      "Random Forest Sorted Feature Importance:  [  3   5   6   1   2   0   4 560  43  52  50  58  55  56 561  57  54 562\n",
      " 565 564  51  48 566 567  25  41  20  53 570 568 563  97 357  59 402 271\n",
      " 313  46 111 114 476 115 571  21  49 112 483 324 108  45 299  35 426 327\n",
      " 207 317 335 538  88  93 117 134  85 528 502 231 270 220 276 411 194 128\n",
      " 340 203 364  79 121 434 385 239 263 209 361 421 215 326 408  13 213 468\n",
      " 382  34 542 267 499 543  16 132 126 287 350 302 517 193 372 235 225 496\n",
      "  23 182 127 109 440 363 120 102 545  15 379 223 232 347 210 222 277  44\n",
      " 259 519 105  18 180 447  40 550 455 348 529 118 275 119  91 493 419 284\n",
      "  87  98 356 477 443  10 457 514 431 490 358  33 367 186 444 293 505  24\n",
      " 212 202 116 211 306 548 377 292 183 214 461 226  82 437 221 135 257 217\n",
      " 430 460 136 482 123 491  19 492 532 506 524 540 503 122 525 522 365 534\n",
      " 368 486 199  94 283 466 192 485 129 230 389  31 219 106 330 349 185 107\n",
      " 366 224 184 281 290  38 395 236 187  95 489 238 403 133 218  83 515 237\n",
      " 338 432 282 113 266 234  81 337  99 285 227 260 328 526 400 438 190 331\n",
      " 188 381 197   8 264 454 369 422 201 516 497 495 339 258 305 383 401 439\n",
      " 544 481  11 345 101 342 393 386 417 547 130 206 484 195 208 406 370 288\n",
      " 189  90 318 458 425 181 488 205 520 233 351 216 198 346 240 274 399 269\n",
      " 535 536 446 301 336 125 229 530 418 471 286 450 373 413 323 397 329 527\n",
      " 442 204 428 196 508 191 376 494 384 549 451 110 303 241 315 272  96  86\n",
      " 295 100 414  14 459 504 531 470 464 512 427 433 405 228 341 539  36 537\n",
      " 298 533 452 424 507   9 435 500 344 479 415 375 316 513  17 469  47  84\n",
      " 510 392 320 104 449 423 322 396  39 353 501 509  89  92 200 475  28 312\n",
      " 541 456 371 261 310  22 409 487 289 398 103 360 314 441 410 546 474 321\n",
      " 291 308 278 294 325 268 297 394 521 311 265 131 304 498 300  30 416 518\n",
      " 332 448 390 465 523 445 309 354 333 462 467 362 359 355 334  80 262 378\n",
      " 380 280 279 404  42 480 124 352 296 319 343 420 453 391 436  27 472  12\n",
      " 307 478  26 374 159 429 463 412  76 256 388 165 569  29 141  73  32 169\n",
      "   7 273 166 407 176 473 167  37 152 138 248 155 178 251 387 553 158 162\n",
      " 254 160 168 161  74 153 242 151  69 177 142 246 148 253 551  70  65 559\n",
      "  60 249 558  72 555 137 556  61 139 157 163  68 179 164 170 171 172 173\n",
      " 174 175 243 154 244 245 247 557 250 252 255 156 552  62  78  63  64  66\n",
      "  67  71  75  77 140 554 143 144 145 511 146 147 149 150]\n",
      "HyperParameterTuning Function Executed\n",
      "Random Forest Best Parameters:  {'max_depth': 16, 'n_estimators': 4}\n",
      "Random Forest Best Score:  0.9681083189208947\n",
      "Logistic Regression Test Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97    230137\n",
      "           1       1.00      1.00      1.00   1868745\n",
      "\n",
      "    accuracy                           0.99   2098882\n",
      "   macro avg       0.98      0.99      0.98   2098882\n",
      "weighted avg       0.99      0.99      0.99   2098882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RFClassifier()\n",
    "rf_clf,y_predict_train, y_predict_test = rf.randomForestClassifier(x_train,x_test, y_train)\n",
    "print(\"randomForestClassifier Function Executed\")\n",
    "print(\"Random Forest Train Accuracy: \",rf.rfTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Random Forest Test Accuracy: \",rf.rfTestAccuracy(y_test,y_predict_test))\n",
    "print(\"Random Forest Feature Importance: \",rf.rfFeatureImportance(rf_clf))\n",
    "print(\"Random Forest Sorted Feature Importance: \",rf.sortedRFFeatureImportanceIndicies(rf_clf))\n",
    "gscv_rfc = rf.hyperParameterTuning(rf_clf,x_train,y_train)\n",
    "print(\"HyperParameterTuning Function Executed\")\n",
    "print(\"Random Forest Best Parameters: \",rf.bestParams(gscv_rfc))\n",
    "print(\"Random Forest Best Score: \",rf.bestScore(gscv_rfc))\n",
    "print(\"Random Forest Test Report: \\n\", rf.rfTestReport(y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Importance\n",
      "3        interest_rate    0.651533\n",
      "5        loan_to_value    0.058696\n",
      "2            loan_term    0.047473\n",
      "6       debt_to_income    0.046865\n",
      "1       property_value    0.042515\n",
      "..                 ...         ...\n",
      "141  county_code_09001    0.000000\n",
      "76   county_code_05073    0.000000\n",
      "77   county_code_05091    0.000000\n",
      "253  county_code_42115    0.000000\n",
      "152  county_code_13297    0.000000\n",
      "\n",
      "[572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have already trained the Random Forest model (rf_model) and X_train contains your training features\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display feature importances and feature names\n",
    "feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importances\n",
    "print(feature_importances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(r\"C:\\Users\\Forcessofnature\\Downloads\\rf_coef.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportVectorMachine():\n",
    "    \n",
    "    def dataPreProcess(self,x_train,x_test):\n",
    "        \"\"\"Pre-process the data to standardize it, otherwise the grid search will take much longer\n",
    "\n",
    "        Args:\n",
    "            x_train (_type_): pandas dataframe\n",
    "            x_test (_type_): pandas dataframe\n",
    "\n",
    "        Returns:\n",
    "            _type_: pandas dataframe\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        # Initialize StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit scaler to training data and transform training data\n",
    "        scaled_x_train = x_train #scaler.fit_transform(x_train)\n",
    "\n",
    "        # Transform test data using the scaler fitted on training data\n",
    "        scaled_x_test = x_test #scaler.transform(x_test)\n",
    "        \n",
    "        # -------------------------------\n",
    "        return scaled_x_train, scaled_x_test\n",
    "\n",
    "    def SVCClassifier(self,scaled_x_train,scaled_x_test, y_train):\n",
    "        \"\"\"Create a SVC classifier and train it. gamma = 'auto'\n",
    "\n",
    "        Args:\n",
    "            scaled_x_train (_type_): pandas dataframe\n",
    "            scaled_x_test (_type_): pandas dataframe\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: numpy array, numpy array\n",
    "        \"\"\"\n",
    "        from sklearn.svm import SVC\n",
    "        # Initialize the SVC model with gamma = 'auto'\n",
    "        svc_clf = SVC(gamma='auto')\n",
    "\n",
    "        # Train the model on the training data\n",
    "        svc_clf.fit(scaled_x_train, y_train)\n",
    "\n",
    "        # Make predictions on the training and testing data\n",
    "        y_predict_train = svc_clf.predict(scaled_x_train)\n",
    "        y_predict_test = svc_clf.predict(scaled_x_test)\n",
    "        # -------------------------------\n",
    "        return y_predict_train,y_predict_test\n",
    "    \n",
    "\n",
    "    def SVCTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"Return accuracy on the training set using the accuracy_score method\n",
    "\n",
    "        Args:\n",
    "            y_train (_type_): pandas series\n",
    "            y_predict_train (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        train_accuracy = accuracy_score(y_train, y_predict_train)\n",
    "       \n",
    "        # -------------------------------\n",
    "        return train_accuracy\n",
    "\n",
    "    def SVCTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"Return accuracy on the test set using the accuracy_score method\n",
    "\n",
    "        Args:\n",
    "            y_train (_type_): pandas series\n",
    "            y_predict_train (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        test_accuracy = accuracy_score(y_test, y_predict_test)\n",
    "        \n",
    "        return test_accuracy\n",
    "    \n",
    "    def SVMBestScore(self, scaled_x_train, y_train):\n",
    "        \"\"\"Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear) return_train_score = True and gamma = 'auto'\n",
    "\n",
    "        Args:\n",
    "            scaled_x_train (_type_): pandas dataframe\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: GridSearchCV object, float\n",
    "        \"\"\"\n",
    "        from sklearn.svm import SVC\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "        svm_parameters = {'kernel':('linear', 'rbf'), 'C':[0.01, 0.1, 1.0]}\n",
    "        \n",
    "        # Initialize SVC model\n",
    "        svm_model = SVC(gamma='auto')\n",
    "\n",
    "        # Create GridSearchCV object\n",
    "        svm_cv = GridSearchCV(estimator=svm_model, param_grid=svm_parameters, return_train_score=True)\n",
    "\n",
    "        # Fit the GridSearchCV object to the training data\n",
    "        svm_cv.fit(scaled_x_train, y_train)\n",
    "\n",
    "        # Get the best mean cross-validated score obtained during the grid search\n",
    "        best_score = svm_cv.best_score_\n",
    "        # -------------------------------\n",
    "        \n",
    "        return svm_cv, best_score\n",
    "    \n",
    "    # points [1]\n",
    "    def SVCClassifierParam(self,svm_cv,scaled_x_train,scaled_x_test,y_train):\n",
    "        \"\"\"Calculate the training and test set predicted values after hyperparameter tuning and standardization.\n",
    "\n",
    "        Args:\n",
    "            svm_cv (_type_): GridSearchCV object\n",
    "            scaled_x_train (_type_): pandas dataframe\n",
    "            scaled_x_test (_type_): pandas dataframe\n",
    "            y_train (_type_): pandas series\n",
    "\n",
    "        Returns:\n",
    "            _type_: numpy series, numpy series\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the best estimator from the GridSearchCV object\n",
    "        best_estimator = svm_cv.best_estimator_\n",
    "\n",
    "        # Train the best estimator on the standardized training data\n",
    "        best_estimator.fit(scaled_x_train, y_train)\n",
    "\n",
    "        # Make predictions on the standardized training and test data\n",
    "        y_predict_train = best_estimator.predict(scaled_x_train)\n",
    "        y_predict_test = best_estimator.predict(scaled_x_test)\n",
    "       \n",
    "        # -------------------------------\n",
    "        return y_predict_train,y_predict_test\n",
    "\n",
    "    # points [1]\n",
    "    def svcTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"Return accuracy (on the training set) using the accuracy_score method\n",
    "\n",
    "        Args:\n",
    "            y_train (_type_): pandas serie\n",
    "            y_predict_train (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        train_accuracy = accuracy_score(y_train, y_predict_train)\n",
    "       \n",
    "        # -------------------------------\n",
    "        return train_accuracy\n",
    "\n",
    "    # points [1]\n",
    "    def svcTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"Return accuracy (on the test set) using the accuracy_score method.\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        test_accuracy = accuracy_score(y_test, y_predict_test)\n",
    "        \n",
    "        # -------------------------------\n",
    "        return test_accuracy\n",
    "    \n",
    "    def SVMRankTestScore(self,svm_cv):\n",
    "        \"\"\"Return the rank test score for all hyperparameter values that you obtained\n",
    "\n",
    "        Args:\n",
    "            svm_cv (_type_): GridSearchCV object\n",
    "\n",
    "        Returns:\n",
    "            _type_: int array\n",
    "        \"\"\"\n",
    "        # Get the rank test scores from the cv_results_ dictionary\n",
    "        rank_test_score = svm_cv.cv_results_['rank_test_score']\n",
    "       \n",
    "        # -------------------------------\n",
    "        return rank_test_score\n",
    "    \n",
    "\n",
    "    def SVMMeanTestScore(self,svm_cv):\n",
    "        \"\"\"Return mean test score for all of hyperparameter values that you obtained\n",
    "\n",
    "        Args:\n",
    "            svm_cv (_type_): GridSearchCV object\n",
    "\n",
    "        Returns:\n",
    "            _type_: float array\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the mean test scores from the cv_results_ dictionary\n",
    "        mean_test_score = svm_cv.cv_results_['mean_test_score']\n",
    "       \n",
    "        # -------------------------------\n",
    "        return mean_test_score\n",
    "    \n",
    "    def svcTestReport(self,y_test,y_predict_test):\n",
    "        \"\"\"Report classification\n",
    "\n",
    "        Args:\n",
    "            y_test (_type_): pandas series\n",
    "            y_predict_test (_type_): numpy array\n",
    "\n",
    "        Returns:\n",
    "            _type_: float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        # Calculate accuracy (not a standard approach for regression)\n",
    "       \n",
    "        class_report = classification_report(y_test, y_predict_test)\n",
    "       \n",
    "        return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataPreProcess Function Executed\n"
     ]
    }
   ],
   "source": [
    "svm = SupportVectorMachine()\n",
    "scaled_x_train, scaled_x_test = svm.dataPreProcess(x_train,x_test)\n",
    "print(\"dataPreProcess Function Executed\")\n",
    "y_predict_train,y_predict_test = svm.SVCClassifier(scaled_x_train,scaled_x_test, y_train)\n",
    "print(\"SVCClassifier Function Executed\")\n",
    "print(\"Support Vector Machine Train Accuracy: \",svm.SVCTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Support Vector Machine Test Accuracy: \",svm.SVCTestAccuracy(y_test,y_predict_test))\n",
    "svm_cv, best_score = svm.SVMBestScore(scaled_x_train, y_train)\n",
    "print(\"Support Vector Machine Best Score: \", best_score)\n",
    "y_predict_train,y_predict_test = svm.SVCClassifierParam(svm_cv,scaled_x_train,scaled_x_test,y_train)\n",
    "print(\"SVCClassifierParam Function Executed\")\n",
    "print(\"Support Vector Machine Train Accuracy: \",svm.svcTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Support Vector Machine Test Accuracy: \",svm.svcTestAccuracy(y_test,y_predict_test))\n",
    "print(\"Support Vector Machine Rank Test Score: \",svm.SVMRankTestScore(svm_cv))\n",
    "print(\"Support Vector Machine Mean Test Score: \",svm.SVMMeanTestScore(svm_cv))\n",
    "print(\"Random Forest Test Report: \\n\", rf.rfTestReport(y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm = SupportVectorMachine()\n",
    "scaled_x_train, scaled_x_test = svm.dataPreProcess(x_train,x_test)\n",
    "print(\"dataPreProcess Function Executed\")\n",
    "y_predict_train,y_predict_test = svm.SVCClassifier(scaled_x_train,scaled_x_test, y_train)\n",
    "print(\"SVCClassifier Function Executed\")\n",
    "print(\"Support Vector Machine Train Accuracy: \",svm.SVCTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Support Vector Machine Test Accuracy: \",svm.SVCTestAccuracy(y_test,y_predict_test))\n",
    "svm_cv, best_score = svm.SVMBestScore(scaled_x_train, y_train)\n",
    "print(\"Support Vector Machine Best Score: \", best_score)\n",
    "y_predict_train,y_predict_test = svm.SVCClassifierParam(svm_cv,scaled_x_train,scaled_x_test,y_train)\n",
    "print(\"SVCClassifierParam Function Executed\")\n",
    "print(\"Support Vector Machine Train Accuracy: \",svm.svcTrainAccuracy(y_train,y_predict_train))\n",
    "print(\"Support Vector Machine Test Accuracy: \",svm.svcTestAccuracy(y_test,y_predict_test))\n",
    "print(\"Support Vector Machine Rank Test Score: \",svm.SVMRankTestScore(svm_cv))\n",
    "print(\"Support Vector Machine Mean Test Score: \",svm.SVMMeanTestScore(svm_cv))\n",
    "print(\"Random Forest Test Report: \\n\", rf.rfTestReport(y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SupportVectorMachine()\n",
    "scaled_x_train, scaled_x_test = svm.dataPreProcess(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23376206, -0.28560737,  0.29337732, ..., -0.00090375,\n",
       "        -0.207969  , -0.11157982],\n",
       "       [ 0.00181803, -0.07525053,  0.29337732, ..., -0.00090375,\n",
       "        -0.207969  , -0.11157982],\n",
       "       [-0.07313927, -0.08439648,  0.29337732, ..., -0.00090375,\n",
       "        -0.207969  , -0.11157982],\n",
       "       ...,\n",
       "       [ 0.13031625,  0.12596036,  0.29337732, ..., -0.00090375,\n",
       "        -0.207969  , -0.11157982],\n",
       "       [-0.11597202, -0.19414788,  0.29337732, ..., -0.00090375,\n",
       "        -0.207969  , -0.11157982],\n",
       "       [-0.29801118, -0.24902358,  0.29337732, ..., -0.00090375,\n",
       "        -0.207969  , -0.11157982]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>property_value</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>income_log</th>\n",
       "      <th>loan_to_value</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>race_ethnicity_2 or more minority races|Free Form Text Only</th>\n",
       "      <th>race_ethnicity_2 or more minority races|Hispanic or Latino</th>\n",
       "      <th>race_ethnicity_2 or more minority races|Joint</th>\n",
       "      <th>...</th>\n",
       "      <th>derived_sex_Male</th>\n",
       "      <th>derived_sex_Sex Not Available</th>\n",
       "      <th>applicant_age_25-34</th>\n",
       "      <th>applicant_age_35-44</th>\n",
       "      <th>applicant_age_45-54</th>\n",
       "      <th>applicant_age_55-64</th>\n",
       "      <th>applicant_age_65-74</th>\n",
       "      <th>applicant_age_9999</th>\n",
       "      <th>applicant_age_&lt;25</th>\n",
       "      <th>applicant_age_&gt;74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>780221</th>\n",
       "      <td>175000.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>5.500</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>3804.347826</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641494</th>\n",
       "      <td>395000.0</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>6.250</td>\n",
       "      <td>4.770685</td>\n",
       "      <td>0.951807</td>\n",
       "      <td>3376.068376</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085703</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>2826.086957</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762092</th>\n",
       "      <td>775000.0</td>\n",
       "      <td>1205000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>3.875</td>\n",
       "      <td>5.023881</td>\n",
       "      <td>0.643154</td>\n",
       "      <td>5132.450331</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604853</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>8.200</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>1418.918919</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584061</th>\n",
       "      <td>425000.0</td>\n",
       "      <td>525000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>5.125</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>3346.456693</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839420</th>\n",
       "      <td>665000.0</td>\n",
       "      <td>735000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>5.625</td>\n",
       "      <td>5.583496</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>2509.433962</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187450</th>\n",
       "      <td>515000.0</td>\n",
       "      <td>635000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>4.125</td>\n",
       "      <td>4.812184</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>4221.311475</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626992</th>\n",
       "      <td>285000.0</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>5.225</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2226.562500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826776</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>3.250</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>2395.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2098882 rows  572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loan_amount  property_value  loan_term  interest_rate  income_log  \\\n",
       "780221      175000.0        185000.0      360.0          5.500    3.850148   \n",
       "2641494     395000.0        415000.0      360.0          6.250    4.770685   \n",
       "1085703     325000.0        405000.0      360.0          2.625    4.753590   \n",
       "5762092     775000.0       1205000.0      360.0          3.875    5.023881   \n",
       "6604853     105000.0        145000.0      240.0          8.200    4.317488   \n",
       "...              ...             ...        ...            ...         ...   \n",
       "7584061     425000.0        525000.0      360.0          5.125    4.852030   \n",
       "839420      665000.0        735000.0      360.0          5.625    5.583496   \n",
       "7187450     515000.0        635000.0      360.0          4.125    4.812184   \n",
       "5626992     285000.0        285000.0      360.0          5.225    4.859812   \n",
       "3826776     115000.0        225000.0      360.0          3.250    3.891820   \n",
       "\n",
       "         loan_to_value  debt_to_income  \\\n",
       "780221        0.945946     3804.347826   \n",
       "2641494       0.951807     3376.068376   \n",
       "1085703       0.802469     2826.086957   \n",
       "5762092       0.643154     5132.450331   \n",
       "6604853       0.724138     1418.918919   \n",
       "...                ...             ...   \n",
       "7584061       0.809524     3346.456693   \n",
       "839420        0.904762     2509.433962   \n",
       "7187450       0.811024     4221.311475   \n",
       "5626992       1.000000     2226.562500   \n",
       "3826776       0.511111     2395.833333   \n",
       "\n",
       "         race_ethnicity_2 or more minority races|Free Form Text Only  \\\n",
       "780221                                               False             \n",
       "2641494                                              False             \n",
       "1085703                                              False             \n",
       "5762092                                              False             \n",
       "6604853                                              False             \n",
       "...                                                    ...             \n",
       "7584061                                              False             \n",
       "839420                                               False             \n",
       "7187450                                              False             \n",
       "5626992                                              False             \n",
       "3826776                                              False             \n",
       "\n",
       "         race_ethnicity_2 or more minority races|Hispanic or Latino  \\\n",
       "780221                                               False            \n",
       "2641494                                              False            \n",
       "1085703                                              False            \n",
       "5762092                                              False            \n",
       "6604853                                              False            \n",
       "...                                                    ...            \n",
       "7584061                                              False            \n",
       "839420                                               False            \n",
       "7187450                                              False            \n",
       "5626992                                              False            \n",
       "3826776                                              False            \n",
       "\n",
       "         race_ethnicity_2 or more minority races|Joint  ...  derived_sex_Male  \\\n",
       "780221                                           False  ...              True   \n",
       "2641494                                          False  ...             False   \n",
       "1085703                                          False  ...             False   \n",
       "5762092                                          False  ...             False   \n",
       "6604853                                          False  ...             False   \n",
       "...                                                ...  ...               ...   \n",
       "7584061                                          False  ...              True   \n",
       "839420                                           False  ...             False   \n",
       "7187450                                          False  ...             False   \n",
       "5626992                                          False  ...             False   \n",
       "3826776                                          False  ...             False   \n",
       "\n",
       "         derived_sex_Sex Not Available  applicant_age_25-34  \\\n",
       "780221                           False                 True   \n",
       "2641494                          False                False   \n",
       "1085703                           True                False   \n",
       "5762092                           True                False   \n",
       "6604853                          False                False   \n",
       "...                                ...                  ...   \n",
       "7584061                          False                False   \n",
       "839420                           False                False   \n",
       "7187450                          False                False   \n",
       "5626992                          False                False   \n",
       "3826776                          False                False   \n",
       "\n",
       "         applicant_age_35-44  applicant_age_45-54  applicant_age_55-64  \\\n",
       "780221                 False                False                False   \n",
       "2641494                False                False                 True   \n",
       "1085703                False                 True                False   \n",
       "5762092                 True                False                False   \n",
       "6604853                False                 True                False   \n",
       "...                      ...                  ...                  ...   \n",
       "7584061                 True                False                False   \n",
       "839420                  True                False                False   \n",
       "7187450                 True                False                False   \n",
       "5626992                 True                False                False   \n",
       "3826776                False                 True                False   \n",
       "\n",
       "         applicant_age_65-74  applicant_age_9999  applicant_age_<25  \\\n",
       "780221                 False               False              False   \n",
       "2641494                False               False              False   \n",
       "1085703                False               False              False   \n",
       "5762092                False               False              False   \n",
       "6604853                False               False              False   \n",
       "...                      ...                 ...                ...   \n",
       "7584061                False               False              False   \n",
       "839420                 False               False              False   \n",
       "7187450                False               False              False   \n",
       "5626992                False               False              False   \n",
       "3826776                False               False              False   \n",
       "\n",
       "         applicant_age_>74  \n",
       "780221               False  \n",
       "2641494              False  \n",
       "1085703              False  \n",
       "5762092              False  \n",
       "6604853              False  \n",
       "...                    ...  \n",
       "7584061              False  \n",
       "839420               False  \n",
       "7187450              False  \n",
       "5626992              False  \n",
       "3826776              False  \n",
       "\n",
       "[2098882 rows x 572 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse_6242",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
