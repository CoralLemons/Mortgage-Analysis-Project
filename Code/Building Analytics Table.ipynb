{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "106d6d16-296c-45af-8349-deacade8a270",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount point already exists.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DecimalType, FloatType\n",
    "from pyspark.sql.functions import col, create_map, lit, concat_ws, array, array_distinct, expr\n",
    "from itertools import chain\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"DataProcessing\").getOrCreate()\n",
    "\n",
    "# Mount the Blob Storage container\n",
    "storage_account_name = \"SECRET\"\n",
    "storage_account_access_key = \"SECRET\"\n",
    "blob_container = \"project-data\"\n",
    "mount_point = \"/mnt/6242ProjectData\"\n",
    "\n",
    "# Check if the mount point is already mounted\n",
    "if any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    print(\"Mount point already exists.\")\n",
    "else:\n",
    "    # Mount the Blob Storage container\n",
    "    dbutils.fs.mount(\n",
    "        source=f\"wasbs://{blob_container}@{storage_account_name}.blob.core.windows.net\",\n",
    "        mount_point=mount_point,\n",
    "        extra_configs={\n",
    "            f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_access_key\n",
    "        }\n",
    "    )\n",
    "    print(\"Mount point successfully created.\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"activity_year\", StringType(), True),\n",
    "    StructField(\"lei\", StringType(), True),\n",
    "    StructField(\"derived_msa_md\", StringType(), True),\n",
    "    StructField(\"state_code\", StringType(), True),\n",
    "    StructField(\"county_code\", StringType(), True),\n",
    "    StructField(\"census_tract\", StringType(), True),\n",
    "    StructField(\"conforming_loan_limit\", StringType(), True),\n",
    "    StructField(\"derived_loan_product_type\", StringType(), True),\n",
    "    StructField(\"derived_dwelling_category\", StringType(), True),\n",
    "    StructField(\"derived_ethnicity\", StringType(), True),\n",
    "    StructField(\"derived_race\", StringType(), True),\n",
    "    StructField(\"derived_sex\", StringType(), True),\n",
    "    StructField(\"action_taken\", StringType(), True),\n",
    "    StructField(\"purchaser_type\", StringType(), True),\n",
    "    StructField(\"preapproval\", StringType(), True),\n",
    "    StructField(\"loan_type\", StringType(), True),\n",
    "    StructField(\"loan_purpose\", StringType(), True),\n",
    "    StructField(\"lien_status\", StringType(), True),\n",
    "    StructField(\"reverse_mortgage\", StringType(), True),\n",
    "    StructField(\"open_end_line_of_credit\", StringType(), True),\n",
    "    StructField(\"business_or_commercial_purpose\", StringType(), True),\n",
    "    StructField(\"loan_amount\", StringType(), True),\n",
    "    StructField(\"combined_loan_to_value_ratio\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with high precision)\n",
    "    StructField(\"interest_rate\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with high precision)\n",
    "    StructField(\"rate_spread\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with high precision)\n",
    "    StructField(\"hoepa_status\", StringType(), True), #string\n",
    "    StructField(\"total_loan_costs\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with .2f precision)\n",
    "    StructField(\"total_points_and_fees\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with .2f precision)\n",
    "    StructField(\"origination_charges\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with .2f precision)\n",
    "    StructField(\"discount_points\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with .2f precision)\n",
    "    StructField(\"lender_credits\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as decimal with high precision)\n",
    "    StructField(\"loan_term\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as integer)\n",
    "    StructField(\"prepayment_penalty_term\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as integer)\n",
    "    StructField(\"intro_rate_period\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as integer)\n",
    "    StructField(\"negative_amortization\", StringType(), True), #String\n",
    "    StructField(\"interest_only_payment\", StringType(), True), #String\n",
    "    StructField(\"balloon_payment\", StringType(), True), #String\n",
    "    StructField(\"other_nonamortizing_features\", StringType(), True), #String\n",
    "    StructField(\"property_value\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as integer)\n",
    "    StructField(\"construction_method\", StringType(), True), #String\n",
    "    StructField(\"occupancy_type\", StringType(), True), #String\n",
    "    StructField(\"manufactured_home_secured_property_type\", StringType(), True), #String\n",
    "    StructField(\"manufactured_home_land_property_interest\", StringType(), True), #String\n",
    "    StructField(\"total_units\", StringType(), True), #replace 5-24 with 15, Replace 25-49 with 37, replace 50-99 with 75, replace 100-149 with 125, replace 149 with 150, then cast as int\n",
    "    StructField(\"multifamily_affordable_units\", StringType(), True), #String (replace \"Exempt\" with -99.000 then cast as integer)\n",
    "    StructField(\"income\", StringType(), True), #String (replace \"Exempt\" with -inf then cast as integer)\n",
    "    StructField(\"debt_to_income_ratio\", StringType(), True), #Replace <20% with 20, replace 20%-<30% with 25, replace 30%-<36% with 33, replace 50-60% with 55, replace >60% with 60, replace Exempt with -99 then cast as col/100 with decimal precision of 0.00\n",
    "    StructField(\"applicant_credit_score_type\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_credit_score_type\", StringType(), True), #String\n",
    "    StructField(\"applicant_ethnicity_1\", StringType(), True), #String\n",
    "    StructField(\"applicant_ethnicity_2\", StringType(), True), #String\n",
    "    StructField(\"applicant_ethnicity_3\", StringType(), True), #String\n",
    "    StructField(\"applicant_ethnicity_4\", StringType(), True), #String\n",
    "    StructField(\"applicant_ethnicity_5\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_ethnicity_1\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_ethnicity_2\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_ethnicity_3\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_ethnicity_4\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_ethnicity_5\", StringType(), True), #String\n",
    "    StructField(\"applicant_ethnicity_observed\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_ethnicity_observed\", StringType(), True), #String\n",
    "    StructField(\"applicant_race_1\", StringType(), True), #String\n",
    "    StructField(\"applicant_race_2\", StringType(), True), #String\n",
    "    StructField(\"applicant_race_3\", StringType(), True), #String\n",
    "    StructField(\"applicant_race_4\", StringType(), True), #String\n",
    "    StructField(\"applicant_race_5\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_race_1\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_race_2\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_race_3\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_race_4\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_race_5\", StringType(), True), #String\n",
    "    StructField(\"applicant_race_observed\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_race_observed\", StringType(), True), #String\n",
    "    StructField(\"applicant_sex\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_sex\", StringType(), True), #String\n",
    "    StructField(\"applicant_sex_observed\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_sex_observed\", StringType(), True), #String\n",
    "    StructField(\"applicant_age\", StringType(), True), #String (replace 8888 with '-99')\n",
    "    StructField(\"co_applicant_age\", StringType(), True), #String (replace 8888 and 9999 with '-99')\n",
    "    StructField(\"applicant_age_above_62\", StringType(), True), #String\n",
    "    StructField(\"co_applicant_age_above_62\", StringType(), True), #String\n",
    "    StructField(\"submission_of_application\", StringType(), True), #String\n",
    "    StructField(\"initially_payable_to_institution\", StringType(), True), #String\n",
    "    StructField(\"aus_1\", StringType(), True), #String\n",
    "    StructField(\"aus_2\", StringType(), True), #String\n",
    "    StructField(\"aus_3\", StringType(), True), #String\n",
    "    StructField(\"aus_4\", StringType(), True), #String\n",
    "    StructField(\"aus_5\", StringType(), True), #String\n",
    "    StructField(\"denial_reason_1\", StringType(), True), #String\n",
    "    StructField(\"denial_reason_2\", StringType(), True), #String\n",
    "    StructField(\"denial_reason_3\", StringType(), True), #String\n",
    "    StructField(\"denial_reason_4\", StringType(), True), #String\n",
    "    StructField(\"tract_population\", StringType(), True), #\tInt\n",
    "    StructField(\"tract_minority_population_percent\", StringType(), True), # then cast as col/100 then high precision\n",
    "    StructField(\"ffiec_msa_md_median_family_income\", StringType(), True),\n",
    "    StructField(\"tract_to_msa_income_percentage\", StringType(), True),\t# cast as col/100 then high precision\n",
    "    StructField(\"tract_owner_occupied_units\", StringType(), True), #\tInt\n",
    "    StructField(\"tract_one_to_four_family_homes\", StringType(), True), #\tInt\n",
    "    StructField(\"tract_median_age_of_housing_units\", StringType(), True) #\tInt\n",
    "])\n",
    "\n",
    "allYearsAndStates = spark.read.format(\"parquet\").schema(schema).load(\"/mnt/6242ProjectData/allYearsAllStates.parquet\")\n",
    "\n",
    "# Create a temporary view from the DataFrame\n",
    "allYearsAndStates.createOrReplaceTempView(\"allYearsAndStates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e10861c-eae7-4b03-af1e-8cf4012aae4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "analyticsDF = allYearsAndStates.\\\n",
    "    withColumn(\"combined_loan_to_value_ratio\", when(col(\"combined_loan_to_value_ratio\") == \"Exempt\", \"-99.000\").otherwise(col(\"combined_loan_to_value_ratio\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"interest_rate\", when(col(\"interest_rate\") == \"Exempt\", \"-99.000\").otherwise(col(\"interest_rate\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"rate_spread\", when(col(\"rate_spread\") == \"Exempt\", \"-99.000\").otherwise(col(\"rate_spread\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"total_loan_costs\", when(col(\"total_loan_costs\") == \"Exempt\", \"-99.000\").otherwise(col(\"total_loan_costs\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"total_points_and_fees\", when(col(\"total_points_and_fees\") == \"Exempt\", \"-99.000\").otherwise(col(\"total_points_and_fees\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"origination_charges\", when(col(\"origination_charges\") == \"Exempt\", \"-99.000\").otherwise(col(\"origination_charges\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"discount_points\", when(col(\"discount_points\") == \"Exempt\", \"-99.000\").otherwise(col(\"discount_points\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"lender_credits\", when(col(\"lender_credits\") == \"Exempt\", \"-99.000\").otherwise(col(\"lender_credits\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"loan_term\", when(col(\"loan_term\") == \"Exempt\", \"-99.000\").otherwise(col(\"loan_term\").cast(\"integer\")).cast(\"integer\")).\\\n",
    "    withColumn(\"prepayment_penalty_term\", when(col(\"prepayment_penalty_term\") == \"Exempt\", \"-99.000\").otherwise(col(\"prepayment_penalty_term\").cast(\"integer\")).cast(\"integer\")).\\\n",
    "    withColumn(\"intro_rate_period\", when(col(\"intro_rate_period\") == \"Exempt\", \"-99.000\").otherwise(col(\"intro_rate_period\").cast(\"integer\")).cast(\"integer\")).\\\n",
    "    withColumn(\"property_value\", when(col(\"property_value\") == \"Exempt\", \"-99.000\").otherwise(col(\"property_value\").cast(\"integer\")).cast(\"integer\")).\\\n",
    "    withColumn(\"total_units_val\", when(col(\"total_units\") == \"5-24\", \"15\")\n",
    "                             .when(col(\"total_units\") == \"25-49\", \"37\")\n",
    "                             .when(col(\"total_units\") == \"50-99\", \"75\")\n",
    "                             .when(col(\"total_units\") == \"100-149\", \"125\")\n",
    "                             .when(col(\"total_units\") == \">149\", \"150\")\n",
    "                             .otherwise(col(\"total_units\")).cast(\"integer\")).\\\n",
    "    withColumn(\"multifamily_affordable_units\", when(col(\"multifamily_affordable_units\") == \"Exempt\", \"-99.000\").otherwise(col(\"multifamily_affordable_units\").cast(\"integer\")).cast(\"integer\")).\\\n",
    "    withColumn(\"income\", when(col(\"income\") == \"Exempt\", \"-inf\").otherwise(col(\"income\").cast(\"integer\")).cast(\"integer\")).\\\n",
    "    withColumn(\"debt_to_income_ratio_val\", when(col(\"debt_to_income_ratio\") == \"<20%\", \"20\")\n",
    "                                        .when(col(\"debt_to_income_ratio\") == \"20%-<30%\", \"25\")\n",
    "                                        .when(col(\"debt_to_income_ratio\") == \"30%-<36%\", \"33\")\n",
    "                                        .when(col(\"debt_to_income_ratio\") == \"50-60%\", \"55\")\n",
    "                                        .when(col(\"debt_to_income_ratio\") == \">60%\", \"60\")\n",
    "                                        .when(col(\"debt_to_income_ratio\") == \"NA\", \"-99\")\n",
    "                                        .when(col(\"debt_to_income_ratio\") == \"Exempt\", \"-99\")\n",
    "                                        .otherwise(col(\"debt_to_income_ratio\")).cast(\"decimal(10, 5)\")).\\\n",
    "    withColumn(\"applicant_age\", when(col(\"applicant_age\") == \"8888\", \"-99\").otherwise(col(\"applicant_age\"))).\\\n",
    "    withColumn(\"co_applicant_age\", when(col(\"co_applicant_age\").isin(\"8888\", \"9999\"), \"-99\").otherwise(col(\"co_applicant_age\"))).\\\n",
    "    withColumn(\"tract_minority_population_percent\", (col(\"tract_minority_population_percent\") / 100).cast(\"decimal(10,5)\")).\\\n",
    "    withColumn(\"ffiec_msa_md_median_family_income\", col(\"ffiec_msa_md_median_family_income\").cast(\"integer\")).\\\n",
    "    withColumn(\"tract_to_msa_income_percentage\", (col(\"tract_to_msa_income_percentage\") / 100).cast(\"decimal(10,5)\")).\\\n",
    "    withColumn(\"tract_owner_occupied_units\", col(\"tract_owner_occupied_units\").cast(\"integer\")).\\\n",
    "    withColumn(\"tract_one_to_four_family_homes\", col(\"tract_one_to_four_family_homes\").cast(\"integer\")).\\\n",
    "    withColumn(\"tract_median_age_of_housing_units\", col(\"tract_median_age_of_housing_units\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1757690b-71c5-4df2-843c-6892ab3165ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (Rows, Columns) = (100763685, 106)\n",
      "After dropping cols and rows, shape of DataFrame: (Rows, Columns) = (40764739, 70)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# purchaser type\n",
    "purchaser_typeMap = {\n",
    "    \"0\": \"Not applicable\",\n",
    "    \"1\": \"GSE\", # Fannie Mae\n",
    "    \"2\": \"HUD\", # Ginnie Mae\n",
    "    \"3\": \"GSE\", # Freddie Mac\n",
    "    \"4\": \"GSE\", # Farmer Mac\n",
    "    \"5\": \"Private securitizer\",\n",
    "    \"6\": \"Commercial bank, savings bank, or savings association\",\n",
    "    \"71\": \"Credit union, mortgage company, or finance company\",\n",
    "    \"72\": \"Life insurance company\",\n",
    "    \"8\": \"Affiliate institution\",\n",
    "    \"9\": \"Other type of purchaser\"\n",
    "}\n",
    "\n",
    "mapping_expr = create_map([lit(x) for x in chain(*purchaser_typeMap.items())])\n",
    "\n",
    "analyticsDF = analyticsDF.withColumn(\"purchaser_type\", mapping_expr.getItem(col(\"purchaser_type\")))\n",
    "\n",
    "preapprovalMap = {\n",
    "    \"1\": True,\n",
    "    \"2\": False\n",
    "}\n",
    "# preapproval\n",
    "analyticsDF = analyticsDF.withColumn(\"preapproval\", (when(col('preapproval')==\"1\", True).otherwise(False)).cast(\"boolean\"))\n",
    "\n",
    "loan_typeMap = {\n",
    "    \"1\": \"Conventional\",\n",
    "    \"2\": \"FHA\",\n",
    "    \"3\": \"VA\",\n",
    "    \"4\": \"USDA\"\n",
    "}\n",
    "\n",
    "mapping_expr = create_map([lit(x) for x in chain(*loan_typeMap.items())])\n",
    "\n",
    "analyticsDF = analyticsDF.withColumn(\"loan_type\", mapping_expr.getItem(col(\"loan_type\")))\n",
    "\n",
    "hoepa_statusMap = {\n",
    "    \"1\": \"High-Cost\",\n",
    "    \"2\": \"Not High-Cost\",\n",
    "    \"3\": \"Not HOEPA\"\n",
    "}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*hoepa_statusMap.items())])\n",
    "\n",
    "analyticsDF = analyticsDF.withColumn(\"hoepa_status\", mapping_expr.getItem(col(\"hoepa_status\")))\n",
    "construction_methodMap = {\n",
    "    \"1\": \"Site-Built\",\n",
    "    \"2\": \"Manufactured\"\n",
    "}\n",
    "analyticsDF = analyticsDF.withColumn(\"construction_method\", when(col('construction_method')==\"1\", \"Site-Built\").otherwise(\"Manufactured\"))\n",
    "occupancy_typeMap = {\n",
    "    \"1\": \"Principal Residence\",\n",
    "    \"2\": \"Second Residence\",\n",
    "    \"3\": \"Investment\"\n",
    "}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*occupancy_typeMap.items())])\n",
    "\n",
    "analyticsDF = analyticsDF.withColumn(\"occupancy_type\", mapping_expr.getItem(col(\"occupancy_type\")))\n",
    "ethnicityMap = {\n",
    "    \"1\": \"Hispanic or Latino\",\n",
    "    \"11\": \"Hispanic or Latino\", # Mexican\n",
    "    \"12\": \"Hispanic or Latino\", # Puerto Rican\n",
    "    \"13\": \"Hispanic or Latino\", # Cuban\n",
    "    \"14\": \"Hispanic or Latino\", # Other Hispanic or Latino\n",
    "    \"2\": \"Not Hispanic or Latino\",\n",
    "    \"3\": \"Missing\", # Not Provided\n",
    "    \"4\": \"Missing\", # Not applicable\n",
    "    \"5\": \"Missing\" # No co-applicant\n",
    "}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*ethnicityMap.items())])\n",
    "\n",
    "for column in [\"applicant_ethnicity_1\",\"applicant_ethnicity_2\",\"applicant_ethnicity_3\",\"applicant_ethnicity_4\",\"applicant_ethnicity_5\",\"co_applicant_ethnicity_1\",\"co_applicant_ethnicity_2\",\"co_applicant_ethnicity_3\",\"co_applicant_ethnicity_4\",\"co_applicant_ethnicity_5\"]:\n",
    "    analyticsDF = analyticsDF.withColumn(column, mapping_expr.getItem(col(column)))\n",
    "\n",
    "raceMap = {\n",
    "    \"1\": \"American Indian or Alaska Native\",\n",
    "    \"2\": \"Asian\",\n",
    "    \"21\": \"Asian\", # \"Asian Indian\", \n",
    "    \"22\": \"Asian\", #\"Chinese\",\n",
    "    \"23\": \"Asian\", #\"Filipino\",\n",
    "    \"24\": \"Asian\", #\"Japanese\",\n",
    "    \"25\": \"Asian\", #\"Korean\",\n",
    "    \"26\": \"Asian\", #\"Vietnamese\",\n",
    "    \"27\": \"Asian\", #\"Other Asian\",\n",
    "    \"3\": \"Black\",\n",
    "    \"4\": \"Native Hawaiian or Pacific Islander\", #\n",
    "    \"41\": \"Native Hawaiian or Pacific Islander\", #\"Native Hawaiian\",\n",
    "    \"42\": \"Native Hawaiian or Pacific Islander\", #\"Guamanian or Chamorro\",\n",
    "    \"43\": \"Native Hawaiian or Pacific Islander\", #\"Samoan\",\n",
    "    \"44\": \"Native Hawaiian or Pacific Islander\", #\"Other Pacific Islander\",\n",
    "    \"5\": \"White\",\n",
    "    \"6\": \"Missing\",\n",
    "    \"7\": \"Missing\", #NA\n",
    "    \"8\": \"Missing\" # No co-applicant\n",
    "}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*raceMap.items())])\n",
    "\n",
    "for column in [\"applicant_race_1\",\"applicant_race_2\",\"applicant_race_3\",\"applicant_race_4\",\"applicant_race_5\",\"co_applicant_race_1\",\"co_applicant_race_2\",\"co_applicant_race_3\",\"co_applicant_race_4\",\"co_applicant_race_5\"]:\n",
    "    analyticsDF = analyticsDF.withColumn(column, mapping_expr.getItem(col(column)))\n",
    "\n",
    "sexMap = {\n",
    "    \"1\": \"Male\",\n",
    "    \"2\": \"Female\",\n",
    "    \"3\": \"Missing\",\n",
    "    \"4\": \"Missing\", # NA\n",
    "    \"5\": \"Missing\", # No co-applicant\n",
    "    \"6\": \"Both Male and Female\" # should recode to unknown or missing?\n",
    "}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*sexMap.items())])\n",
    "analyticsDF = analyticsDF.withColumn(\"applicant_sex\", mapping_expr.getItem(col(\"applicant_sex\")))\n",
    "analyticsDF = analyticsDF.withColumn(\"co_applicant_sex\", mapping_expr.getItem(col(\"co_applicant_sex\")))\n",
    "\n",
    "denial_reasonMap = {\n",
    "    \"1\": \"Debt-to-income ratio\",\n",
    "    \"2\": \"Employment history\",\n",
    "    \"3\": \"Credit history\",\n",
    "    \"4\": \"Collateral\",\n",
    "    \"5\": \"Insufficient cash (downpayment, closing costs)\",\n",
    "    \"6\": \"Unverifiable information\",\n",
    "    \"7\": \"Credit application incomplete\",\n",
    "    \"8\": \"Mortgage insurance denied\",\n",
    "    \"9\": \"Other\",\n",
    "    \"10\": \"Not applicable\",\n",
    "}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*denial_reasonMap.items())])\n",
    "\n",
    "for column in [\"denial_reason_1\", \"denial_reason_2\", \"denial_reason_3\", \"denial_reason_4\"]:\n",
    "    analyticsDF = analyticsDF.withColumn(column, mapping_expr.getItem(col(column)))\n",
    "\n",
    "paymentMaps = {\n",
    "    \"2\": False,\n",
    "    \"1\": True,\n",
    "    \"1111\": False\n",
    "} # for use with negative_amortization, interest_only_payment, balloon_payment, other_nonamortizing_features, #business_or_commercial_purpose\n",
    "mapping_expr = create_map([lit(x) for x in chain(*paymentMaps.items())])\n",
    "\n",
    "for column in [\"negative_amortization\", \"interest_only_payment\", \"balloon_payment\", \"other_nonamortizing_features\", \"business_or_commercial_purpose\"]:\n",
    "    analyticsDF = analyticsDF.withColumn(column, (mapping_expr.getItem(col(column))).cast(\"boolean\"))\n",
    "\n",
    "    # create joined version of multi-columns:\n",
    "    # applicant_ethnicitys = join applicant_ethnicity_n | after deduplicating and eliminating blanks\n",
    "    # co_applicant_ethnicitys = join co_applicant_ethnicity_n | after deduplicating and eliminating blanks\n",
    "\n",
    "# Join and deduplicate ethnicity columns for applicants\n",
    "analyticsDF = analyticsDF.withColumn(\"applicant_ethnicitys\", \n",
    "                                      concat_ws(\"|\", \n",
    "                                                array_distinct(\n",
    "                                                    array(*[expr(f\"trim({x})\") for x in [\"applicant_ethnicity_1\", \"applicant_ethnicity_2\", \"applicant_ethnicity_3\", \"applicant_ethnicity_4\", \"applicant_ethnicity_5\"] if x is not None])\n",
    "                                                )\n",
    "                                      ))\n",
    "analyticsDF = analyticsDF.withColumn(\"co_applicant_ethnicitys\", \n",
    "                                      concat_ws(\"|\", \n",
    "                                                array_distinct(\n",
    "                                                    array(*[expr(f\"trim({x})\") for x in [\"co_applicant_ethnicity_1\", \"co_applicant_ethnicity_2\", \"co_applicant_ethnicity_3\", \"co_applicant_ethnicity_4\", \"co_applicant_ethnicity_5\"] if x is not None])\n",
    "                                                )\n",
    "                                      ))\n",
    "\n",
    "# Join and deduplicate race columns for applicants\n",
    "analyticsDF = analyticsDF.withColumn(\"applicant_races\", \n",
    "                                      concat_ws(\"|\", \n",
    "                                                array_distinct(\n",
    "                                                    array(*[expr(f\"trim({x})\") for x in [\"applicant_race_1\", \"applicant_race_2\", \"applicant_race_3\", \"applicant_race_4\", \"applicant_race_5\"] if x is not None])\n",
    "                                                )\n",
    "                                      )\n",
    "                                    )\n",
    "analyticsDF = analyticsDF.withColumn(\"co_applicant_races\", \n",
    "                                      concat_ws(\"|\", \n",
    "                                                array_distinct(\n",
    "                                                    array(*[expr(f\"trim({x})\") for x in [\"co_applicant_race_1\", \"co_applicant_race_2\", \"co_applicant_race_3\", \"co_applicant_race_4\", \"co_applicant_race_5\"] if x is not None])\n",
    "                                                )\n",
    "                                      )\n",
    "                                    )\n",
    "analyticsDF = analyticsDF.withColumn(\"denial_reasons\", \n",
    "                                      concat_ws(\"|\", \n",
    "                                                array_distinct(\n",
    "                                                    array(*[expr(f\"trim({x})\") for x in [\"denial_reason_1\", \"denial_reason_2\", \"denial_reason_3\", \"denial_reason_4\"] if x is not None])\n",
    "                                                )\n",
    "                                      )\n",
    "                                    )\n",
    "\n",
    "colsToDrop = [\n",
    "    \"submission_of_application\",\"initially_payable_to_institution\",\"applicant_sex_observed\",\"co_applicant_sex_observed\",\"applicant_race_observed\",\"co_applicant_race_observed\",\"applicant_ethnicity_observed\",\"co_applicant_ethnicity_observed\",\"applicant_ethnicity_1\",\"applicant_ethnicity_2\",\"applicant_ethnicity_3\",\"applicant_ethnicity_4\",\"applicant_ethnicity_5\",\"co_applicant_ethnicity_1\",\"co_applicant_ethnicity_2\",\"co_applicant_ethnicity_3\",\"co_applicant_ethnicity_4\",\"co_applicant_ethnicity_5\",\"applicant_race_1\",\"applicant_race_2\",\"applicant_race_3\",\"applicant_race_4\",\"applicant_race_5\",\"co_applicant_race_1\",\"co_applicant_race_2\",\"co_applicant_race_3\",\"co_applicant_race_4\",\"co_applicant_race_5\",\"applicant_sex\",\"co_applicant_sex\",\"denial_reason_1\",\"denial_reason_2\",\"denial_reason_3\",\"denial_reason_4\", \"manufactured_home_secured_property_type\", \"manufactured_home_land_property_interest\"\n",
    "]\n",
    "\n",
    "colsToKeep = [col for col in analyticsDF.columns if col not in colsToDrop]\n",
    "\n",
    "# filtering and keeping rows\n",
    "# select colsToKeep\n",
    "# drop rows where loan_purpose != \"1\"\n",
    "# drop rows where reverse_mortgage == \"1\"\n",
    "# drop rows where open_end_line_of_credit == \"1\"\n",
    "\n",
    "# If you explicitly need to select columns to keep (though not necessary for filtering), you can use:\n",
    "# Number of rows\n",
    "numRows = analyticsDF.count()\n",
    "\n",
    "# Number of columns\n",
    "numCols = len(analyticsDF.columns)\n",
    "\n",
    "print(\"Shape of DataFrame: (Rows, Columns) = ({}, {})\".format(numRows, numCols))\n",
    "\n",
    "analyticsDF = analyticsDF.select(*colsToKeep)\n",
    "\n",
    "# Apply the row filters again if colsToKeep is used after filtering\n",
    "analyticsDF = analyticsDF.filter(\n",
    "    (col(\"loan_purpose\") == \"1\") & # Home Purchase - should we include refinancing? do two separate models?\n",
    "    (col(\"reverse_mortgage\") != \"1\") & # Not a reverse mortgage\n",
    "    (col(\"open_end_line_of_credit\") != \"1\") # Not an open-end line of credit\n",
    ")\n",
    "# Number of rows\n",
    "numRows = analyticsDF.count()\n",
    "\n",
    "# Number of columns\n",
    "numCols = len(analyticsDF.columns)\n",
    "\n",
    "print(\"After dropping cols and rows, shape of DataFrame: (Rows, Columns) = ({}, {})\".format(numRows, numCols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76b80253-a55c-41ec-9fac-588c470e2d45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analyticsDF.coalesce(1).write.format(\"parquet\").save(\"/mnt/6242ProjectData/fullAnalyticsDF.parquet\")\n",
    "analyticsDFSmall = analyticsDF.filter(col(\"state_code\").isin([\"TX\", \"NY\", \"CA\", \"WA\"])).coalesce(1)\n",
    "analyticsDFSmall.write.format(\"parquet\").save(\"/mnt/6242ProjectData/fullAnalyticsDFSmall.parquet\")\n",
    "analyticsDFSmall.write.format(\"csv\").save(\"/mnt/6242ProjectData/fullAnalyticsDFSmall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e0bec90-5b7b-4107-982b-b004997b1096",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid values for loan_amount:\n",
      "+-----------+\n",
      "|loan_amount|\n",
      "+-----------+\n",
      "+-----------+\n",
      "\n",
      "Invalid values for tract_population:\n",
      "+----------------+\n",
      "|tract_population|\n",
      "+----------------+\n",
      "+----------------+\n",
      "\n",
      "Invalid values for tract_minority_population_percent:\n",
      "+---------------------------------+\n",
      "|tract_minority_population_percent|\n",
      "+---------------------------------+\n",
      "+---------------------------------+\n",
      "\n",
      "Invalid values for ffiec_msa_md_median_family_income:\n",
      "+---------------------------------+\n",
      "|ffiec_msa_md_median_family_income|\n",
      "+---------------------------------+\n",
      "+---------------------------------+\n",
      "\n",
      "Invalid values for tract_to_msa_income_percentage:\n",
      "+------------------------------+\n",
      "|tract_to_msa_income_percentage|\n",
      "+------------------------------+\n",
      "+------------------------------+\n",
      "\n",
      "Invalid values for tract_owner_occupied_units:\n",
      "+--------------------------+\n",
      "|tract_owner_occupied_units|\n",
      "+--------------------------+\n",
      "+--------------------------+\n",
      "\n",
      "Invalid values for tract_one_to_four_family_homes:\n",
      "+------------------------------+\n",
      "|tract_one_to_four_family_homes|\n",
      "+------------------------------+\n",
      "+------------------------------+\n",
      "\n",
      "Invalid values for tract_median_age_of_housing_units:\n",
      "+---------------------------------+\n",
      "|tract_median_age_of_housing_units|\n",
      "+---------------------------------+\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Define UDF to try casting to float\n",
    "def try_cast_to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Register UDF\n",
    "udf_cast_to_float = udf(try_cast_to_float, FloatType())\n",
    "\n",
    "# List of columns to check\n",
    "columns_to_check = [\n",
    "    \"loan_amount\",\n",
    "    \"tract_population\",\n",
    "    \"tract_minority_population_percent\",\n",
    "    \"ffiec_msa_md_median_family_income\",\n",
    "    \"tract_to_msa_income_percentage\",\n",
    "    \"tract_owner_occupied_units\",\n",
    "    \"tract_one_to_four_family_homes\",\n",
    "    \"tract_median_age_of_housing_units\",\n",
    "]\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "for column in columns_to_check:\n",
    "    df_with_cast = allYearsAndStates.withColumn(column + \"_cast\", udf_cast_to_float(allYearsAndStates[column]))\n",
    "    invalid_rows = df_with_cast.filter(df_with_cast[column + \"_cast\"].isNull())\n",
    "    print(f\"Invalid values for {column}:\")\n",
    "    invalid_rows.select(column).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Building Analytics Table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
